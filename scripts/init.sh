#!/bin/bash
# HashData Lightning 2.0 é›†ç¾¤åˆå§‹åŒ–è„šæœ¬
# ä½œè€…: Vance Chen
# 
# åŠŸèƒ½è¯´æ˜:
# - é¦–æ¬¡åˆå§‹åŒ– HashData Lightning é›†ç¾¤
# - åˆ›å»º Docker å·ç”¨äºæ•°æ®æŒä¹…åŒ–
# - è‡ªåŠ¨é…ç½®é›†ç¾¤é—´ SSH é€šä¿¡
# - åˆå§‹åŒ–æ•°æ®åº“å’Œç”¨æˆ·æƒé™
# 
# âš ï¸  é‡è¦æé†’:
# - æ­¤è„šæœ¬ä»…ç”¨äºé¦–æ¬¡åˆå§‹åŒ–ï¼Œä¸åº”é‡å¤æ‰§è¡Œ
# - å¦‚éœ€é‡æ–°åˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡Œ ./scripts/destroy.sh æ¸…ç†ç°æœ‰é›†ç¾¤
# - åˆå§‹åŒ–è¿‡ç¨‹éœ€è¦ 3-10 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…

set -euo pipefail

# è„šæœ¬ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "${SCRIPT_DIR}")"

# åŠ è½½ç¯å¢ƒå˜é‡
if [ -f "${PROJECT_DIR}/hashdata.env" ]; then
    source "${PROJECT_DIR}/hashdata.env"
else
    echo "é”™è¯¯: æœªæ‰¾åˆ°ç¯å¢ƒé…ç½®æ–‡ä»¶ hashdata.env"
    exit 1
fi

# é¢œè‰²è¾“å‡ºå‡½æ•°
print_info() {
    echo -e "\033[32m[ä¿¡æ¯]\033[0m $1"
}

print_warning() {
    echo -e "\033[33m[è­¦å‘Š]\033[0m $1"
}

print_error() {
    echo -e "\033[31m[é”™è¯¯]\033[0m $1"
}

# æ£€æŸ¥ä¾èµ–
check_dependencies() {
    # æ£€æŸ¥ Docker
    if ! command -v docker &> /dev/null; then
        print_error "Docker æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Docker"
        exit 1
    fi
    
    # æ£€æŸ¥ Docker Compose
    if ! command -v docker-compose &> /dev/null && ! docker compose version &> /dev/null; then
        print_error "Docker Compose æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Docker Compose"
        exit 1
    fi
    
    print_info "ä¾èµ–æ£€æŸ¥é€šè¿‡"
}

# æ£€æŸ¥é•œåƒæ˜¯å¦å­˜åœ¨
check_image() {
    if ! docker image inspect "${IMAGE_NAME}:${IMAGE_TAG}" &> /dev/null; then
        print_warning "é•œåƒ ${IMAGE_NAME}:${IMAGE_TAG} ä¸å­˜åœ¨"
        print_info "æ­£åœ¨æ„å»ºé•œåƒ..."
        "${SCRIPT_DIR}/build.sh"
    else
        print_info "é•œåƒ ${IMAGE_NAME}:${IMAGE_TAG} å·²å­˜åœ¨"
    fi
}

# æ£€æŸ¥é›†ç¾¤æ˜¯å¦å·²å­˜åœ¨
check_cluster_exists() {
    local volumes=(
        "hashdata_master_data"
        "hashdata_segment1_data"
        "hashdata_segment2_data"
    )
    
    local existing_volumes=()
    for volume in "${volumes[@]}"; do
        if docker volume ls --filter "name=${volume}" --format "{{.Name}}" | grep -q "${volume}"; then
            existing_volumes+=("${volume}")
        fi
    done
    
    if [ ${#existing_volumes[@]} -gt 0 ]; then
        print_error "âš ï¸  æ£€æµ‹åˆ°å·²å­˜åœ¨çš„é›†ç¾¤æ•°æ®å·ï¼"
        print_error "ç°æœ‰å·: ${existing_volumes[*]}"
        print_error ""
        print_error "æ­¤è„šæœ¬ä»…ç”¨äºé¦–æ¬¡åˆå§‹åŒ–ï¼Œä¸åº”é‡å¤æ‰§è¡Œã€‚"
        print_error "å¦‚éœ€é‡æ–°åˆå§‹åŒ–é›†ç¾¤ï¼Œè¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤æ¸…ç†ç°æœ‰é›†ç¾¤:"
        print_error "  ./scripts/destroy.sh"
        print_error ""
        print_error "å¦‚éœ€å¯åŠ¨ç°æœ‰é›†ç¾¤ï¼Œè¯·ä½¿ç”¨:"
        print_error "  ./scripts/start.sh"
        exit 1
    fi
    
    print_info "âœ… æœªæ£€æµ‹åˆ°ç°æœ‰é›†ç¾¤ï¼Œå¯ä»¥è¿›è¡Œåˆå§‹åŒ–"
}

# æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
check_ports() {
    local ports=("${MASTER_PORT}" "${SEGMENT_PORT_BASE}" "$((SEGMENT_PORT_BASE + 1))")
    
    for port in "${ports[@]}"; do
        if netstat -tuln 2>/dev/null | grep -q ":${port} "; then
            print_error "âŒ ç«¯å£ ${port} å·²è¢«å ç”¨"
            print_error "è¯·ä¿®æ”¹é…ç½®æˆ–åœæ­¢å ç”¨ç«¯å£çš„è¿›ç¨‹"
            exit 1
        fi
    done
    
    print_info "âœ… ç«¯å£æ£€æŸ¥é€šè¿‡"
}



# å¯åŠ¨é›†ç¾¤å®¹å™¨
start_cluster() {
    print_info "ğŸš€ å¯åŠ¨ HashData Lightning 2.0 é›†ç¾¤å®¹å™¨..."
    print_info "ğŸ“¦ æ­£åœ¨åˆ›å»º Docker å·å’Œç½‘ç»œ..."
    
    cd "${PROJECT_DIR}"
    
    # ä½¿ç”¨ç¯å¢ƒå˜é‡æ–‡ä»¶å¯åŠ¨
    if command -v docker-compose &> /dev/null; then
        docker-compose --env-file hashdata.env up -d
    else
        docker compose --env-file hashdata.env up -d
    fi
    
    if [ $? -eq 0 ]; then
        print_info "âœ… é›†ç¾¤å®¹å™¨å¯åŠ¨æˆåŠŸï¼"
        print_info "ğŸ“‹ åˆ›å»ºçš„ Docker å·:"
        print_info "   - hashdata_master_data (Master èŠ‚ç‚¹æ•°æ®)"
        print_info "   - hashdata_segment1_data (Segment1 èŠ‚ç‚¹æ•°æ®)"  
        print_info "   - hashdata_segment2_data (Segment2 èŠ‚ç‚¹æ•°æ®)"
    else
        print_error "âŒ é›†ç¾¤å¯åŠ¨å¤±è´¥"
        print_error "è¯·æ£€æŸ¥ Docker æœåŠ¡çŠ¶æ€å’Œç«¯å£å ç”¨æƒ…å†µ"
        exit 1
    fi
}

# ç­‰å¾…æœåŠ¡åˆå§‹åŒ–å®Œæˆ
wait_for_services() {
    print_info "â³ ç­‰å¾…é›†ç¾¤åˆå§‹åŒ–å®Œæˆ..."
    print_info "ğŸ”§ æ­£åœ¨è¿›è¡Œ: SSHé…ç½®ã€ç”¨æˆ·åˆ›å»ºã€æ•°æ®åº“åˆå§‹åŒ–"
    print_warning "â° æ­¤è¿‡ç¨‹éœ€è¦ 3-10 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…"
    echo
    
    local max_wait=300  # æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    local wait_time=0
    
    while [ $wait_time -lt $max_wait ]; do
        if docker exec hashdata-master su - gpadmin -c "psql -c 'SELECT 1'" &> /dev/null; then
            print_info "âœ… HashData é›†ç¾¤åˆå§‹åŒ–å®Œæˆï¼Œæ•°æ®åº“å·²å°±ç»ªï¼"
            return 0
        fi
        
        echo -n "."
        sleep 5
        wait_time=$((wait_time + 5))
    done
    
    echo
    print_warning "âš ï¸  ç­‰å¾…è¶…æ—¶ï¼Œé›†ç¾¤å¯èƒ½ä»åœ¨åˆå§‹åŒ–ä¸­"
    print_info "ğŸ’¡ å»ºè®®æ“ä½œ:"
    print_info "   1. æŸ¥çœ‹å®¹å™¨æ—¥å¿—: docker logs hashdata-master"
    print_info "   2. æ£€æŸ¥å®¹å™¨çŠ¶æ€: docker ps"
    print_info "   3. ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•è¿æ¥"
}

# æ˜¾ç¤ºé›†ç¾¤çŠ¶æ€
show_cluster_status() {
    print_info "=== é›†ç¾¤çŠ¶æ€ ==="
    
    # æ˜¾ç¤ºå®¹å™¨çŠ¶æ€
    docker ps --filter "name=hashdata-" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
    
    echo
    print_info "=== é›†ç¾¤ä¿¡æ¯ ==="
    print_info "Master èŠ‚ç‚¹: http://localhost:${MASTER_PORT}"
    print_info "ç½‘ç»œå­ç½‘: ${NETWORK_SUBNET}"
    print_info "æ•°æ®å­˜å‚¨: Docker ç®¡ç†çš„å· (hashdata_master_data, hashdata_segment1_data, hashdata_segment2_data)"
    print_info "æ—¥å¿—æŸ¥çœ‹: docker logs <å®¹å™¨å> æˆ–æ•°æ®ç›®å½•ä¸­çš„HashDataæ—¥å¿—æ–‡ä»¶"
    
    echo
    print_info "=== è¿æ¥æ–¹å¼ ==="
    echo "  # è¿æ¥åˆ° Master èŠ‚ç‚¹"
    echo "  docker exec -it hashdata-master su - gpadmin -c \"psql\""
    echo ""
    echo "  # æŸ¥çœ‹é›†ç¾¤é…ç½®"
    echo "  docker exec -it hashdata-master su - gpadmin -c \"psql -c 'SELECT * FROM gp_segment_configuration;'\""
    echo ""
    echo "  # æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—"
    echo "  docker logs hashdata-master"
}

# ä¸»å‡½æ•°
main() {
    print_info "=== HashData Lightning 2.0 é›†ç¾¤åˆå§‹åŒ– ==="
    print_warning "âš ï¸  æ­¤è„šæœ¬ä»…ç”¨äºé¦–æ¬¡åˆå§‹åŒ–é›†ç¾¤"
    echo
    
    check_dependencies
    check_image
    check_cluster_exists
    check_ports
    start_cluster
    wait_for_services
    show_cluster_status
    
    echo
    print_info "ğŸ‰ é›†ç¾¤åˆå§‹åŒ–å®Œæˆï¼"
    print_info "ğŸ“‹ åç»­æ“ä½œæŒ‡å—:"
    print_info "   â€¢ å¯åŠ¨é›†ç¾¤: ./scripts/start.sh"
    print_info "   â€¢ åœæ­¢é›†ç¾¤: ./scripts/stop.sh (ä¿ç•™æ•°æ®)"
    print_info "   â€¢ é”€æ¯é›†ç¾¤: ./scripts/destroy.sh (åˆ é™¤æ‰€æœ‰æ•°æ®)"
    print_info "   â€¢ è¿æ¥æ•°æ®åº“: docker exec -it hashdata-master su - gpadmin -c 'psql'"
}

# æ‰§è¡Œä¸»å‡½æ•°
main "$@" 